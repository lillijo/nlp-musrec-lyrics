{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3deb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Imports\n",
    "import sys \n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "#from sklearn.cluster import DBSCAN\n",
    "import collections\n",
    "#from sklearn.neighbors import NearestNeighbors\n",
    "#from gensim.test.utils import common_texts\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "#from gensim.models.doc2vec import Doc2Vec, TaggedDocument,KeyedVectors \n",
    "#from gensim.test.utils import get_tmpfile\n",
    "#import nltk\n",
    "#from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cef8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210519\n",
      "27143\n",
      "123984\n"
     ]
    }
   ],
   "source": [
    "with open('tracks_train.json','r') as file:\n",
    "    train_docs = json.load(file) \n",
    "print(len(train_docs))\n",
    "with open('tracks_test.json','r') as file:\n",
    "    test_docs = json.load(file) \n",
    "print(len(test_docs))\n",
    "\n",
    "filtereddocs = pickle.load( open( \"counted_bows\", \"rb\" ) ) #train_documents\n",
    "print(len(filtereddocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4e9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents_json = pickle.load( open( \"counted_bows_test\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3f43f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4126\n"
     ]
    }
   ],
   "source": [
    "all_w_k = []\n",
    "for i in bow_vectors.values():    \n",
    "    all_w_k += [int(x) for x in i.keys()]\n",
    "set_wk = set(all_w_k)\n",
    "print(len(set_wk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1121a1c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-d9b33bc84ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_wk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(set_wk[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505dd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_vector(words):\n",
    "    vector = []\n",
    "    for i in list(set_wk):\n",
    "        if str(i) in words:\n",
    "            vector.append(int(words[str(i)]))\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    return vector\n",
    "\n",
    "bow_vectors = {}\n",
    "for doc in filtereddocs:\n",
    "    did = doc[1][0]\n",
    "    if did in train_docs:\n",
    "        bow_vectors[did] = dict_to_vector(train_docs[did]['words'])\n",
    "        #bow_vectors[did] = train_docs[did]['words']\n",
    "    if did in test_docs:\n",
    "        bow_vectors[did] = dict_to_vector(test_docs[did]['words'])\n",
    "        #bow_vectors[did] = test_docs[did]['words']\n",
    "#print(len(bow_vectors))\n",
    "#print(bow_vectors['4252601'])\n",
    "#np_vectors = np.array(list(bow_vectors.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75393681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536 4126\n",
      "(123984, 4126)\n"
     ]
    }
   ],
   "source": [
    "np_vectors = pickle.load( open( \"bow_vectors1.p\", \"rb\" ) )\n",
    "#np_vectors  = np.array(list(bow_vectors.values()))\n",
    "\n",
    "word_counts = np.sum(np_vectors, 0)\n",
    "to_delete = [i for i in range(len(word_counts)) if word_counts[i] > 180000 or word_counts[i] < 30]\n",
    "\n",
    "print(len(to_delete), len(word_counts))\n",
    "#np_vectors = np.delete(np_vectors, to_delete, 0)\n",
    "print(np.shape(np_vectors) )\n",
    "np_vectors_small = np.delete(np_vectors, to_delete, 1)\n",
    "print(np.shape(np_vectors_small) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b026c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np_vectors = np.array(list(bow_vectors.values()))\n",
    "with open(\"bow_vectors1.p\",\"wb\") as inf_json:\n",
    "    pickle.dump(np_vectors_small,inf_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe78d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123984 [  5.60082012   1.2115934   -1.58404199  -1.28377742   2.78026157\n",
      "   2.26953982   2.81396657  -8.97400708   1.75882056   2.50610376\n",
      "   0.10814506  -3.23075919   1.01806087  -0.03298465   0.87926803\n",
      "  -0.50588243  -1.20978913  -0.89778248   2.29363993  -3.60679287\n",
      "  -0.93045357  -1.82296988  -1.30808822  -2.16945148   1.91844061\n",
      "   0.4202481   -0.79957688   2.7171709    0.63653754  -0.96881233\n",
      "  -1.29314285  -0.1621938    2.26032537  -0.02515892   1.18822424\n",
      "  -0.13719202   1.69959856   0.50883139   0.85513438   1.16878393\n",
      "  -0.68376373   0.30575952  -0.34644185   1.95321251   1.98519774\n",
      "  -0.98183511  -1.325814    -0.49732792   1.92799672  -1.94114801\n",
      "   3.17586201  -1.77407584  -1.30839319  -2.89797323  -4.22619108\n",
      "   4.57983388   5.5679175    3.04729063   0.43123507   0.83097138\n",
      "   4.69073922   2.16673812   2.26284358  -4.11616135  -2.47295079\n",
      "  -3.45589556   1.93132825  -2.82642259  -0.54406746  13.92021807\n",
      "   4.08376568   1.81762692 -10.49030678  -6.2536038   -1.35011015\n",
      "   4.08653841  -0.67822216  -2.903912     3.63336937  -6.6508434\n",
      "  -0.86600128  -6.33813582  -1.97126043   3.19026207   6.56441727\n",
      "   4.60720011  -4.00583221   0.52849342  -3.82987867   1.64908015\n",
      "  -2.27199552   0.17793016   1.59108554   1.59366376  -1.17813273\n",
      "  -0.42594294  -0.60207484   0.12876641   1.0622431    0.67657184]\n"
     ]
    }
   ],
   "source": [
    "print(len(princomps),princomps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c78f879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np_vectors = pickle.load( open( \"bow_vectors1.p\", \"rb\" ) )\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "princomps = pca.fit_transform(np_vectors)\n",
    "#X_embedded = TSNE(n_components=2, perplexity=100, learning_rate=600).fit_transform(princomps)\n",
    "with open(\"bow_vectors2.p\",\"wb\") as inf_json:\n",
    "    pickle.dump(princomps,inf_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f723058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint_test_genres():\n",
    "    test_ids = [i[1] for i in test_documents_json]\n",
    "    inf_vecs = pickle.load( open( \"inferred_vectors_dict.p\", \"rb\" ) ) #test_documents\n",
    "    test_vecs = [(inf_vecs[vec[0]],vec[1]) for vec in test_ids if vec[0] in bow_vectors]\n",
    "    X = np.array([i[0] for i in test_vecs])\n",
    "\n",
    "    genres = [i[1] for i in test_vecs]\n",
    "    counter = collections.Counter(genres)\n",
    "    for i in range(len(genres)):\n",
    "        if counter[genres[i]] < 55:\n",
    "            genres[i] = 0\n",
    "    unique_colors = sorted(list(set(genres)),key= lambda x: counter[x])\n",
    "    colors = [unique_colors.index(i) for i in genres]\n",
    "\n",
    "    X_embedded = TSNE(n_components=2, perplexity=50).fit_transform(X)\n",
    "\n",
    "    with open('genres.json','r') as file2:\n",
    "        genre_names = json.load(file2) \n",
    "    genre_mapping = {i: [x['name'] for x in genre_names if x['genre_id'] == i] for i in unique_colors}\n",
    "\n",
    "    plt.figure(figsize=(25, 25))\n",
    "\n",
    "    plt.scatter([i[0] for i in X_embedded],[i[1] for i in X_embedded],c=colors,cmap='tab20', s=20)\n",
    "\n",
    "    plt.scatter([-60 for i in list(set(colors))],[(i+30)*2 for i in list(set(colors))],c=list(set(colors)), cmap='tab20', s=20)\n",
    "    for i in range(len(unique_colors)):\n",
    "        txt = genre_mapping[unique_colors[i]]\n",
    "        plt.annotate(txt, (-59, (i+30)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "891b1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bow_vectors[0])\n",
    "\n",
    "def paint_test_genres_bow():\n",
    "    test_ids = [i[1] for i in test_documents_json ]\n",
    "    test_vecs = [(bow_vectors[vec[0]],vec[1]) for vec in test_ids if vec[0] in bow_vectors]\n",
    "    X = np.array([i[0] for i in test_vecs])\n",
    "    #print(X[0])\n",
    "\n",
    "    genres = [i[1] for i in test_vecs]\n",
    "    counter = collections.Counter(genres)\n",
    "    for i in range(len(genres)):\n",
    "        if counter[genres[i]] < 55:\n",
    "            genres[i] = 0\n",
    "    unique_colors = sorted(list(set(genres)),key= lambda x: counter[x])\n",
    "    colors = [unique_colors.index(i) for i in genres]\n",
    "\n",
    "    X_embedded = TSNE(n_components=2, perplexity=50).fit_transform(X)\n",
    "\n",
    "    with open('genres.json','r') as file2:\n",
    "        genre_names = json.load(file2) \n",
    "    genre_mapping = {i: [x['name'] for x in genre_names if x['genre_id'] == i] for i in unique_colors}\n",
    "\n",
    "    plt.figure(figsize=(25, 25))\n",
    "\n",
    "    plt.scatter([i[0] for i in X_embedded],[i[1] for i in X_embedded],c=colors,cmap='tab20', s=20)\n",
    "    #for i in range(len(X_embedded)):\n",
    "    #    plt.annotate(test_ids[i][0], (X_embedded[i][0], X_embedded[i][1]))\n",
    "    plt.scatter([-40 for i in list(set(colors))],[(i) for i in list(set(colors))],c=list(set(colors)), cmap='tab20', s=20)\n",
    "    for i in range(len(unique_colors)):\n",
    "        txt = genre_mapping[unique_colors[i]]\n",
    "        plt.annotate(txt, (-39, (i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4743c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X_emb = TSNE(n_components=2, perplexity=50, learning_rate=500).fit_transform(princomps[5000:15000])\n",
    "#df = pd.DataFrame(np_vectors[:10000,300:360])\n",
    "#pd.plotting.scatter_matrix(df, alpha=0.2, figsize=(25,25))\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "covMatrix = np.cov(np_vectors[:5000,300:400],bias=True)\n",
    "sn.heatmap(covMatrix, annot=True, fmt='g')\n",
    "plt.show()\n",
    "\n",
    "#plt.figure(figsize=(25, 25))\n",
    "#plt.scatter([i[6] for i in princomps],[i[7] for i in princomps],c=[i[8] for i in princomps],cmap='gist_rainbow', s=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848daff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
